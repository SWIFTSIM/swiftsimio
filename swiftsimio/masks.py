"""
Loading functions and objects that use masked information from the SWIFT
snapshots.
"""

import warnings
import h5py
import numpy as np
from typing import Union

from swiftsimio.metadata.objects import SWIFTMetadata
from swiftsimio.objects import InvalidSnapshot, cosmo_array, cosmo_quantity
from swiftsimio.accelerated import ranges_from_array

_DEFAULT_SAFE_PADDING = 0.2
_GROUPCAT_OUTPUT_TYPES = ["FOF", "SOAP"]


class SWIFTMask(object):
    """
    Main masking object. This can have masks for any present particle field in it.
    Pass in the SWIFTMetadata.
    """

    group_mapping: dict | None = None
    group_size_mapping: dict | None = None

    def __init__(
        self,
        metadata: SWIFTMetadata,
        spatial_only=True,
        safe_padding: Union[bool, float] = _DEFAULT_SAFE_PADDING,
    ):
        """
        SWIFTMask constructor

        Takes the SWIFT metadata and enables individual property-by-property masking
        when reading from snapshots. Please note that when masking like this
        order-in-file is not preserved, i.e. the 7th particle may not be the
        7th particle in the file.

        Parameters
        ----------
        metadata : SWIFTMetadata
            Metadata specifying masking for reading of snapshots

        spatial_only : bool, optional
            If True (the default), you can only constrain spatially.
            However, this is significantly faster and considerably
            more memory efficient (~ bytes per cell, rather than
            ~ bytes per particle).

        safe_padding : bool or float, optional
            If snapshot does not specify bounding box of cell particles (``MinPositions``,
            ``MaxPositions``), pad the mask to gurantee that *all* particles in requested
            spatial region(s) are selected. If the bounding box metadata is present, this
            argument is ignored. The default (``0.2``) is to pad by 0.2 times the cell
            length. Padding can be disabled (``False``) or set to a different fraction of
            the cell length (e.g. ``0.5``). Only entire cells are loaded, but if the
            region boundary is more than ``safe_padding`` from a cell boundary the
            neighbouring cell is not read. Switching off can reduce I/O load by up to a
            factor of 30 in some cases (but a few particles in region could be missing).
            See https://swiftsimio.readthedocs.io/en/latest/masking/index.html for further
            details.
        """

        self.metadata = metadata
        self.units = metadata.units
        self.spatial_only = spatial_only
        self.safe_padding = {True: _DEFAULT_SAFE_PADDING, False: 1.0}.get(
            safe_padding, safe_padding
        )

        if not self.metadata.masking_valid:
            raise NotImplementedError(
                f"Masking not supported for {self.metadata.output_type} filetype"
            )

        if self.metadata.partial_snapshot:
            raise InvalidSnapshot(
                "You cannot use masks on partial snapshots. Please use the virtual "
                "file generated by SWIFT (use snapshot.hdf5, not snapshot.0.hdf5)."
            )

        self._unpack_cell_metadata()

        if not spatial_only:
            self._generate_empty_masks()

    def _generate_mapping_dictionary(self) -> dict[str, str]:
        """
        Creates cross-links between 'group names' and their underlying cell metadata
        names. Allows for pointers to be used instead of re-creating masks.
        """

        if self.group_mapping is not None:
            return self.group_mapping

        if self.metadata.shared_cell_counts is None:
            # Each and every particle type has its own cell counts, offsets,
            # and hence masks.
            self.group_mapping = {
                group: f"_{group}" for group in self.metadata.present_group_names
            }
        else:
            # We actually only have _one_ mask!
            self.group_mapping = {
                group: "_shared" for group in self.metadata.present_group_names
            }

        return self.group_mapping

    def _generate_size_mapping_dictionary(self) -> dict[str, str]:
        """
        Creates cross-links between 'group names' and their underlying cell metadata
        names. Allows for pointers to be used instead of re-creating masks.
        """

        if self.group_size_mapping is not None:
            return self.group_size_mapping

        if self.metadata.shared_cell_counts is None:
            # Each and every particle type has its own cell counts, offsets,
            # and hence masks.
            self.group_size_mapping = {
                f"{group}_size": f"_{group}_size"
                for group in self.metadata.present_group_names
            }
        else:
            # We actually only have _one_ mask!
            self.group_size_mapping = {
                f"{group}_size": "_shared_size"
                for group in self.metadata.present_group_names
            }

        return self.group_size_mapping

    def _generate_update_list(self) -> list[str]:
        """
        Gets a list of internal mask variables that need to be updated when
        we change the spatial mask.
        """

        if self.metadata.shared_cell_counts is None:
            # Each and every particle type has its own cell counts, offsets,
            # and hence masks.
            return [f"_{group}" for group in self.metadata.present_group_names]
        else:
            # We actually only have _one_ mask!
            return ["_shared"]

    def __getattr__(self, name):
        """
        Overloads the getattr method to allow for direct access to the masks
        for each particle type.
        """
        mappings = {
            **self._generate_mapping_dictionary(),
            **self._generate_size_mapping_dictionary(),
        }

        underlying_name = mappings.get(name, None)

        if underlying_name is not None:
            return getattr(self, underlying_name)

        raise AttributeError(f"Attribute {name} not found in SWIFTMask")

    def _generate_empty_masks(self):
        """
        Generates the empty (i.e. all False) masks for all available particle
        types.
        """

        mapping = self._generate_mapping_dictionary()

        if self.metadata.shared_cell_counts is not None:
            size = getattr(
                self.metadata, f"n_{self.metadata.shared_cell_counts.lower()}"
            )
            self._shared = np.ones(size, dtype=bool)
            self._shared_size = size

        else:
            # Create empty masks for each and every particle type.
            for group_name, data_name in mapping.items():
                size = getattr(self.metadata, f"n_{group_name}")
                setattr(self, data_name, np.ones(size, dtype=bool))
                setattr(self, f"{data_name}_size", size)

        return

    def _unpack_cell_metadata(self):
        """
        Unpacks the cell metadata into local (to the class) variables. We do not
        read in information for empty cells.
        """

        # Reset this in case for any reason we have messed them up

        self.counts = {}
        self.offsets = {}
        self.minpositions = {}
        self.maxpositions = {}

        cell_handle = self.units.handle["Cells"]
        count_handle = cell_handle["Counts"]
        metadata_handle = cell_handle["Meta-data"]
        centers_handle = cell_handle["Centres"]
        if (
            "MinPositions" in cell_handle.keys()
            and "MaxPositions" in cell_handle.keys()
        ):
            # Older versions of SWIFT don't have this information
            minpos_handle = cell_handle["MinPositions"]
            maxpos_handle = cell_handle["MaxPositions"]
        else:
            minpos_handle, maxpos_handle = None, None

        try:
            offset_handle = cell_handle["OffsetsInFile"]
        except KeyError:
            # Previous version of SWIFT did not have distributed
            # file i/o implemented
            offset_handle = cell_handle["Offsets"]

        if self.metadata.shared_cell_counts is not None:
            # Single - called _shared.
            self.offsets["shared"] = offset_handle[self.metadata.shared_cell_counts][:]
            self.counts["shared"] = count_handle[self.metadata.shared_cell_counts][:]
        else:
            for group, group_name in zip(
                self.metadata.present_groups, self.metadata.present_group_names
            ):
                self.offsets[group_name] = offset_handle[group][:]
                self.counts[group_name] = count_handle[group][:]

        if minpos_handle is not None and maxpos_handle is not None:
            for group, group_name in zip(
                self.metadata.present_groups, self.metadata.present_group_names
            ):
                self.minpositions[group_name] = np.where(
                    centers_handle[:] - 0.5 * metadata_handle.attrs["size"]
                    < minpos_handle[group][:],
                    centers_handle[:] - 0.5 * metadata_handle.attrs["size"],
                    minpos_handle[group][:],
                )
                self.maxpositions[group_name] = np.where(
                    centers_handle[:] + 0.5 * metadata_handle.attrs["size"]
                    > maxpos_handle[group][:],
                    centers_handle[:] + 0.5 * metadata_handle.attrs["size"],
                    maxpos_handle[group][:],
                )
        else:
            # be conservative: pad (default by 0.2 cell) in case particles drifed
            # (unless for group catalogues)
            pad_cells = (
                0
                if self.metadata.output_type in _GROUPCAT_OUTPUT_TYPES
                else self.safe_padding
            )
            if self.metadata.output_type not in _GROUPCAT_OUTPUT_TYPES:
                warnings.warn(
                    "Snapshot does not contain Cells/MinPositions and Cells/MaxPositions"
                    f" metadata. Padding region by {pad_cells} times cell length to"
                    " account for drifted particles. This behaviour can be"
                    " configured/disabled with the `safe_padding` parameter when creating"
                    " the mask. See "
                    "https://swiftsimio.readthedocs.io/en/latest/masking/index.html"
                    " for further details."
                )
            # +/- 0.5 here is the cell size itself:
            self.minpositions["shared"] = (
                centers_handle[:] - (pad_cells + 0.5) * metadata_handle.attrs["size"]
            )
            self.maxpositions["shared"] = (
                centers_handle + (pad_cells + 0.5) * metadata_handle.attrs["size"]
            )
        # Only want to compute this once (even if it is fast, we do not
        # have a reliable stable sort in the case where cells do not
        # contain at least one of each type of particle).
        self.cell_sort = None

        # Now perform sort:
        for key in self.offsets.keys():
            offsets = self.offsets[key]
            counts = self.counts[key]

            # When using MPI, we cannot assume that these are sorted.
            if self.cell_sort is None:
                # Only compute once; not stable between particle
                # types if some datasets do not have particles in a cell!
                self.cell_sort = np.argsort(offsets)

            self.offsets[key] = offsets[self.cell_sort]
            self.counts[key] = counts[self.cell_sort]

        # Also need to sort centers in the same way
        self.centers = cosmo_array(
            centers_handle[:][self.cell_sort],
            units=self.units.length,
            comoving=True,
            scale_factor=self.metadata.scale_factor,
            scale_exponent=1,
        )
        # And sort min & max positions, too.
        for k in self.minpositions.keys():
            self.minpositions[k] = cosmo_array(
                self.minpositions[k][self.cell_sort],
                units=self.units.length,
                comoving=True,
                scale_factor=self.metadata.scale_factor,
                scale_exponent=1,
            )
        for k in self.maxpositions.keys():
            self.maxpositions[k] = cosmo_array(
                self.maxpositions[k][self.cell_sort],
                units=self.units.length,
                comoving=True,
                scale_factor=self.metadata.scale_factor,
                scale_exponent=1,
            )
        if minpos_handle is None and maxpos_handle is None:
            for group_name in self.metadata.present_group_names:
                self.minpositions[group_name] = self.minpositions["shared"]
                self.maxpositions[group_name] = self.maxpositions["shared"]

        # Note that we cannot assume that these are cubic, unfortunately.
        self.cell_size = cosmo_array(
            metadata_handle.attrs["size"],
            units=self.units.length,
            comoving=True,
            scale_factor=self.metadata.scale_factor,
            scale_exponent=1,
        )

        return

    def constrain_mask(
        self,
        group_name: str,
        quantity: str,
        lower: cosmo_quantity,
        upper: cosmo_quantity,
    ):
        """
        Constrains the mask further for a given particle type, and bounds a
        quantity between lower and upper values.

        We update the mask such that

            lower < group_name.quantity <= upper

        The quantities must have units attached.

        Parameters
        ----------
        group_name : str
            particle type

        quantity : str
            quantity being constrained

        lower : ~swiftsimio.objects.cosmo_quantity
            constraint lower bound

        upper : ~swiftsimio.objects.cosmo_quantity
            constraint upper bound

        See Also
        --------

        constrain_spatial : method to generate spatially constrained cell mask

        """

        if self.spatial_only:
            raise ValueError(
                "You cannot constrain a mask if spatial_only=True. "
                "Please re-initialise the SWIFTMask object with spatial_only=False"
            )

        mapping = self._generate_mapping_dictionary()
        data_name = mapping[group_name]

        current_mask = getattr(self, data_name)

        group_metadata = getattr(self.metadata, f"{group_name}_properties")
        unit_dict = {
            k: v for k, v in zip(group_metadata.field_names, group_metadata.field_units)
        }

        unit = unit_dict[quantity]

        handle_dict = {
            k: v for k, v in zip(group_metadata.field_names, group_metadata.field_paths)
        }

        handle = handle_dict[quantity]

        physical_dict = {
            k: v
            for k, v in zip(group_metadata.field_names, group_metadata.field_physicals)
        }

        physical = physical_dict[quantity]

        cosmologies_dict = {
            k: v
            for k, v in zip(
                group_metadata.field_names, group_metadata.field_cosmologies
            )
        }

        cosmology_factor = cosmologies_dict[quantity]

        # Load in the relevant data.

        with h5py.File(self.metadata.filename, "r") as file:
            # Surprisingly this is faster than just using the boolean
            # indexing because h5py has slow indexing routines.
            data = cosmo_array(
                np.take(file[handle], np.where(current_mask)[0], axis=0),
                units=unit,
                comoving=not physical,
                cosmo_factor=cosmology_factor,
            )

        new_mask = np.logical_and.reduce([data > lower, data <= upper])

        current_mask[current_mask] = new_mask

        setattr(self, data_name, current_mask)

        return

    def _generate_cell_mask(self, restrict):
        """
        Generates spatially restricted mask for cell

        Takes the cell metadata and finds the mask for the _cells_ that are
        within the spatial region defined by the spatial mask. Not for
        user use.

        Parameters
        ----------

        restrict : list
            Restrict is a 3 length list that contains length two arrays giving
            the lower and upper bounds for that axis, e.g.

            restrict = [
                [0.5, 0.7],
                [0.1, 0.9],
                [0.0, 0.1]
            ]

            These values must have units associated with them.

        Raises
        ------
        ValueError
            If the mask boundaries are outside the interval [-Lbox/2, 3*Lbox/2].

        Returns
        -------

        cell_mask : np.array[bool]
            mask to indicate which cells are within the specified spatial range
        """

        if self.metadata.output_type in _GROUPCAT_OUTPUT_TYPES:
            cell_mask = {"shared": np.ones(len(self.centers), dtype=bool)}
        else:
            # particles may drift from their cells, mask each type separately
            cell_mask = {
                group_name: np.ones(len(self.centers), dtype=bool)
                for group_name in self.metadata.present_group_names
            }

        for dimension in range(0, 3):
            lower = restrict[dimension][0]
            upper = restrict[dimension][1]
            boxsize = self.metadata.boxsize[dimension]
            if np.logical_or.reduce(
                (
                    lower < -boxsize / 2,
                    upper < -boxsize / 2,
                    lower > 3 * boxsize / 2,
                    upper > 3 * boxsize / 2,
                )
            ):
                # because we're only going to make one periodic copy on either side,
                # we're in trouble
                raise ValueError(
                    "Mask region boundaries must be in interval [-boxsize/2, 3*boxsize/2]"
                    f" along {'xyz'[dimension]}-axis."
                )
            if restrict[dimension] is None or np.abs(upper - lower) > boxsize:
                # keep everything along this axis
                continue
            if upper < lower:
                # inverted case, convert to a "normal" case in target window
                if lower > boxsize / 2:
                    lower -= boxsize
                elif upper < boxsize / 2:  # don't shift both else we get the whole box!
                    upper += boxsize
            group_names = (
                ["shared"]
                if self.metadata.output_type in _GROUPCAT_OUTPUT_TYPES
                else self.metadata.present_group_names
            )
            for group_name in group_names:
                # selection intersects one of the 3 periodic copies of a cell:
                this_mask = np.logical_or.reduce(
                    [
                        np.logical_and(
                            self.maxpositions[group_name][
                                cell_mask[group_name], dimension
                            ]
                            + shift * boxsize
                            > lower,
                            self.minpositions[group_name][
                                cell_mask[group_name], dimension
                            ]
                            + shift * boxsize
                            < upper,
                        )
                        for shift in (-1, 0, 1)
                    ]
                )
                cell_mask[group_name][cell_mask[group_name]] = this_mask

        return cell_mask

    def _update_spatial_mask(self, restrict, data_name: str, cell_mask: dict):
        """
        Updates the particle mask using the cell mask.

        We actually overwrite all non-used cells with False, rather than the
        inverse, as we assume initially that we want to write all particles in,
        and we want to respect other masks that may have been applied to the data.

        Parameters
        ----------

        restrict : list
            currently unused

        data_name : str
            underlying data to update (e.g. _gas, _shared)

        cell_mask : dict
            cell mask used to update the particle mask
        """

        count_name = data_name[1:]  # Remove the underscore

        for group_name in self.metadata.present_group_names:
            if self.spatial_only:
                counts = self.counts[count_name][cell_mask[count_name]]
                offsets = self.offsets[count_name][cell_mask[count_name]]

                this_mask = [[o, c + o] for c, o in zip(counts, offsets)]

                setattr(self, data_name, np.array(this_mask))
                setattr(self, f"{data_name}_size", np.sum(counts))

            else:
                counts = self.counts[count_name][~cell_mask[count_name]]
                offsets = self.offsets[count_name][~cell_mask[count_name]]

                # We must do the whole boolean mask business.
                this_mask = getattr(self, data_name)

                for count, offset in zip(counts, offsets):
                    this_mask[offset : count + offset] = False

        return

    def constrain_spatial(self, restrict, intersect: bool = False):
        """
        Uses the cell metadata to create a spatial mask.

        This mask is necessarily approximate and is coarse-grained to the cell size.

        Parameters
        ----------

        restrict : list
            length 3 list of length two arrays giving the lower and
            upper bounds for that axis, e.g.

            restrict = [
                [0.5, 0.7],
                [0.1, 0.9],
                [0.0, 0.1]

            ]

            These values must have units associated with them. It is also acceptable
            to have a row as None to not restrict in this direction.

        intersect : bool
            If `True`, intersect the spatial mask with any existing spatial mask to
            select two (or more) regions with repeated calls to `constrain_spatial`.
            By default (`False`) any existing mask is overwritten.

        See Also
        -------

        constrain_mask : method to further refine mask
        """

        if hasattr(self, "cell_mask") and intersect:
            # we already have a mask and are in intersect mode
            new_mask = self._generate_cell_mask(restrict)
            for group_name in self.metadata.present_group_names:
                self.cell_mask[group_name] = np.logical_or(
                    self.cell_mask[group_name], new_mask[group_name]
                )
        else:
            # we just make a new mask
            self.cell_mask = self._generate_cell_mask(restrict)

        for mask in self._generate_update_list():
            self._update_spatial_mask(restrict, mask, self.cell_mask)

        return

    def convert_masks_to_ranges(self):
        """
        Converts the masks to range masks so that they take up less space.

        This is non-reversible. It is also not required, but can help save space
        on highly constrained machines before you start reading in the data.

        If you don't know what you are doing please don't use this.
        """

        # Spatial only already comes like this!
        if not self.spatial_only:
            # We must do the whole boolean mask stuff. To do that, we
            # First, convert each boolean mask into an integer mask
            # Use the accelerate.ranges_from_array function to convert
            # This into a set of ranges.
            for mask in self._generate_update_list():
                where_array = np.where(getattr(self, mask))[0]
                setattr(self, f"{mask}_size", where_array.size)
                setattr(self, mask, ranges_from_array(where_array))

        return

    def constrain_index(self, index: int):
        """
        Constrain the mask to a single row.

        Intended for use with SOAP catalogues, mask to read only a single row.

        Parameters
        ----------
        index : int
            The index of the row to select.
        """

        if not self.metadata.homogeneous_arrays:
            raise RuntimeError(
                "Cannot constrain to a single row in a non-homogeneous array; you "
                f"currently are using a {self.metadata.output_type} file"
            )

        if not self.spatial_only:
            raise RuntimeError(
                "Cannot constrain to a single row in a non-spatial mask; you currently "
                "are using a non-spatial mask"
            )

        for mask in self._generate_update_list():
            setattr(self, mask, np.array([[index, index + 1]]))
            setattr(self, f"{mask}_size", 1)

        return

    def constrain_indices(self, indices: list[int]):
        """
        Constrain the mask to a list of rows.
        Parameters
        ----------
        indices : list[int]
            An list of the indices of the rows to mask.
        """

        if not self.metadata.homogeneous_arrays:
            raise RuntimeError(
                "Cannot constrain to a single row in a non-homogeneous array; you "
                f"currently are using a {self.metadata.output_type} file"
            )

        if self.spatial_only:
            if len(indices) > 1000:
                warnings.warn(
                    "You are constraining a large number of indices with a spatial "
                    "mask, potentially leading to lots of overlap. You should "
                    "use a non-spatial mask (i.e. spatial_only=False)"
                )

            for mask in self._generate_update_list():
                setattr(self, mask, np.array([[i, i + 1] for i in indices]))
                setattr(self, f"{mask}_size", len(indices))

        else:
            for mask in self._generate_update_list():
                comparison_array = np.zeros(getattr(self, mask).size, dtype=bool)
                comparison_array[indices] = True
                setattr(
                    self, mask, np.logical_and(getattr(self, mask), comparison_array)
                )

        return

    def get_masked_counts_offsets(
        self,
    ) -> tuple[dict[str, np.array], dict[str, np.array]]:
        """
        Returns the particle counts and offsets in cells selected by the mask

        Returns
        -------

        Dict[str, np.array], Dict[str, np.array]
            Dictionaries containing the particle offets and counts for each particle
            type. For example, the particle counts dictionary would be of the form

            .. code-block:: python

                {"gas": [g_0, g_1, ...],
                 "dark matter": [bh_0, bh_1, ...], ...}

            where the keys would be each of the particle types and values are arrays
            of the number of corresponding particles in each cell (in this case there
            would be g_0 gas particles in the first cell, g_1 in the second, etc.).
            The structure of the dictionaries is the same for the offsets, with the
            arrays now storing the offset of the first particle in the cell.

        """

        if self.spatial_only:
            masked_counts = {}
            current_offsets = {}
            if not hasattr(self, "cell_mask"):
                raise RuntimeError(
                    "Subset writing requires specifying a cell mask. Please use "
                    "constrain_spatial with a suitable restrict array to generate one."
                )
            for part_type, counts in self.counts.items():
                masked_counts[part_type] = counts * self.cell_mask[part_type]

                current_offsets[part_type] = np.zeros(counts.size, dtype=np.int64)
                running_sum = 0
                for i in range(len(counts)):
                    current_offsets[part_type][i] = running_sum
                    running_sum += masked_counts[part_type][i]

            return masked_counts, current_offsets
        else:
            raise ("Only applies on spatial only masks")
